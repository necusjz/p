---
title: 机器学习
date: 2017-03-23 12:18:04
tags:
  - MachineLearning
---
## 引言
经验通常以数据形式存在
机器学习是研究关于学习算法的学问
**模型**指全局性结果，**模式**指局部性结果。
## 基本术语
记录的集合称为一个**数据集**（data set）
特征张成的空间称为特征空间（feature space）
一个样本（sample）称为一个特征向量（feature vector）
训练样本组成的集合称为**训练集**（training set）
拥有了标记（label）信息的样本，称为样例（example）。
**学习任务：**
* 二分类任务（binary classification）
* 多分类任务（multi-class classfication）
* 回归任务（regression）

<!--more-->
**聚类**（clustering）学习自动形成簇（cluster），学习过程中使用的训练样本通常不拥有标记信息。
分类和回归是**监督学习**（supervised learning）的代表，聚类是**无监督学习**（unsupervised learning）的代表。
学得模型适用于新样本的能力，称为泛化（generalization）能力。
样本空间中全体样本服从一个未知**分布**（distribution），每个样本都是独立地从这个分布上采样获得的，即独立同分布（independent and identically distributed）。
## 假设空间
归纳（induction）和演绎（deduction）是科学推理的两大基本手段：
* 归纳是从特殊到一般的泛化过程
* 演绎是从一般到特殊的特化（specialization）过程

学习过程可以看作一个在所有假设（hypothesis）组成的空间中进行搜索的过程
存在着一个与训练集一致的假设集合，称之为**版本空间**（version space）。
## 归纳偏好
有效的机器学习算法必有其归纳偏好
归纳偏好可看作对假设进行选择的启发式或价值观
**奥卡姆剃刀**（Occam's razor）：
若有多个假设与观察一致，则选最简单的那个。
**没有免费的午餐**定理（No Free Lunch Theorem）：
一个学习算法 a，若它在某些问题上比学习算法 b 好，则必然存在另一些问题，在那里 b 比 a 好。总误差与学习算法无关。
> NFL 定理假设了 f 的均匀分布，实际情形并非如此，我们只关注正在试图解决的问题。

脱离**具体问题**，空泛地谈论“什么学习算法更好”毫无意义。若考虑所有潜在的问题，则所有学习算法一样好。
归纳偏好与问题是否相配，往往会起到决定性的作用。
## 发展历程
典型的决策树学习以信息论为基础，以信息熵的最小化为目标。
**统计学习**的代表性技术是支持向量机（Support Vector Machine)
深度学习，狭义地说就是很多层的神经网络。
深度学习模型拥有大量参数，若数据样本少，则很容易**过拟合**。
## 应用现状
### 大数据时代的三大关键技术
机器学习：提供数据分析能力
云计算：提供数据处理能力
众包（crowdsourcing）：提供数据标记能力
### 数据挖掘的两大支撑
* 数据库领域：提供数据管理技术
* 机器学习领域：提供数据分析技术

数据挖掘是从海量数据中发掘知识
要建立输入与输出之间的联系，内核必然需要机器学习技术。
> 机器学习不仅在信息科学中占有重要地位，还具有一定的自然科学探索色彩。

## 阅读材料
多释原则（principle of multiple explanations）：
主张保留与经验观察一致的所有假设。
萨缪尔跳棋程序，否证了计算机不可能完成事先没有显式编程好的任务的假设，是最早在计算机上执行非数值计算任务的程序之一。

[习题答案](http://blog.csdn.net/icefire_tyh/article/details/52065224)
