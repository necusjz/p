---
title: 数组
tags:
  - CLRS
abbrlink: 872565161
date: 2020-12-25 22:36:57
---
在大部分编程语言中，数组都是从 0 开始编号的，但你是否下意识地想过，为什么数组要从 0 开始编号，而不是从 1 开始呢？ 从 1 开始不是更符合人类的思维习惯吗？

## 如何实现随机访问？
`数组`（Array）是一种线性表数据结构。它**用一组连续的内存空间，来存储一组具有相同类型的数据**。

顾名思义，`线性表`（Linear List）就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/05.png)
<!--more-->

而与它相对立的概念是`非线性表`，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，**数据之间并不是简单的前后关系**：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/06.png)

**连续的内存空间和相同类型的数据**。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：`随机访问`。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，**为了保证连续性，就需要做大量的数据搬移工作**。

我们拿一个长度为 10 的 int 类型的数组 int[] a = new int\[10]来举例。在我画的这个图中，计算机给数组 a\[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/07.png)

我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：
```cpp
a[i]_address = base_address + i * data_type_size
```

其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。

我在面试的时候，常常会问数组和链表的区别，很多人都回答说，“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，**数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)**。

## 低效的“插入”和“删除”
数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。

### 插入操作
假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k~n 这部分的元素都顺序地往后挪一位。

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以**平均情况时间复杂度为 (1+2+...+n)/n=O(n)**。

如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，**如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合**。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

假设数组 a\[10] 中存储了如下 5 个元素：a, b, c, d, e，我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a\[5]，将 a\[2] 赋值为 x 即可。最后，数组中的元素如下： a, b, x, d, e, c：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/08.png)

利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的**时间复杂度就会降为 O(1)**。这个处理思想在快排中也会用到。

### 删除操作
跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；**平均情况时间复杂度也为 O(n)**。

实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？数组 a\[10] 中存储了 8 个元素：a, b, c, d, e, f, g, h。现在，我们要依次删除 a, b, c 三个元素：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/09.png)

为了避免 d, e, f, g, h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。**当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作**，这样就大大减少了删除操作导致的数据搬移。

如果你了解 JVM，你会发现，这不就是 **JVM 标记清除垃圾回收算法的核心思想**吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要**学习它背后的思想和处理技巧，这些东西才是最有价值的**。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。

## 警惕数组的访问越界问题
首先，我请你来分析一下这段 C 语言代码的运行结果：
```cpp
int main(int argc, char* argv[]) {
    int i = 0;
    int arr[3] = {0};
    for(; i<=3; i++) {
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}
```

你发现问题了吗？这段代码的运行结果并非是打印三行“hello word”，而是会无限打印“hello world”。因为，数组大小为 3：a\[0]，a\[1]，a\[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i<=3 而非 i<3，所以当 i=3 时，数组 a\[3] 访问越界。我们知道，在 C 语言中，**只要不是访问受限的内存，所有的内存空间都是可以自由访问的**。根据我们前面讲的数组寻址公式，a\[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a\[3]=0 就相当于 i=0，所以就会导致代码无限循环。

这种情况下，一般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例子，debug 的难度非常的大。而且，**很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统**，所以写代码的时候一定要警惕数组越界。但**并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做**，像 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 java.lang.ArrayIndexOutOfBoundsException：
```java
int[] a = new int[3];
a[3] = 10;
```

## 容器能否完全替代数组？
针对数组类型，很多语言都提供了容器类，比如 Java 中的 `ArrayList`、C++ STL 中的 `vector`。

我个人觉得，ArrayList 最大的优势就是可以**将很多数组操作的细节封装起来**。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是**支持动态扩容**。如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。

不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，**最好在创建 ArrayList 的时候事先指定数据大小**。比如我们要从数据库中取出 10000 条数据放入 ArrayList。我们看下面这几行代码，你会发现，相比之下，事先指定数据大小可以省掉很多次内存申请和数据搬移操作：
```java
ArrayList<User> users = new ArrayList(10000);
for (int i = 0; i < 10000; ++i) {
    users.add(xxx);
}
```

有些时候，用数组会更合适些，我总结了几点自己的经验：
- **Java ArrayList 无法存储基本类型**，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组；
- 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组；
- 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList\<ArrayList<object\>> array；

我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做**一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器**，成为首选。

## 数组为什么从 0 开始编号
从数组存储的内存模型上来看，“下标”最确切的定义应该是`偏移`（Offset）。前面也讲到，如果用 a 来表示数组的首地址，a\[0] 就是偏移为 0 的位置，也就是首地址，a\[k] 就表示偏移 k 个 type_size 的位置，所以计算 a\[k] 的内存地址只需要用这个公式：
```cpp
a[k]_address = base_address + k * type_size
```

但是，如果数组从 1 开始计数，那我们计算数组元素 a\[k] 的内存地址就会变为：
```cpp
a[k]_address = base_address + (k-1) * type_size
```

对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以**为了减少一次减法操作，数组选择了从 0 开始编号**，而不是从 1 开始。

## LeetCode
[3Sum](https://leetcode.com/problems/3sum/)
[Majority Element](https://leetcode.com/problems/majority-element/)
[First Missing Positive](https://leetcode.com/problems/first-missing-positive/)
