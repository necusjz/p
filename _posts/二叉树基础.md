---
title: 二叉树基础
tags:
  - CLRS
abbrlink: 2225903441
date: 2021-01-03 18:00:37
---
## 树（Tree）
我们首先来看，什么是`树`？我在图中画了几棵树：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/96.png)

树这种数据结构真的很像我们现实生活中的树，这里面每个元素我们叫做“节点”；用来连接相邻节点之间的关系，我们叫做“父子关系”。比如下面这幅图，A 节点就是 B 节点的`父节点`，B 节点是 A 节点的`子节点`。B、C、D 这三个节点的父节点是同一个节点，所以它们之间互称为`兄弟节点`。我们把没有父节点的节点叫做`根节点`，也就是图中的节点 E。我们把没有子节点的节点叫做`叶子节点`，比如图中的 G、H、I、J、K、L 都是叶子节点：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/97.png)
<!--more-->

除此之外，关于树，还有三个比较相似的概念：`高度`（Height）、`深度`（Depth）、`层`（Level）。它们的定义是这样的：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/98.png)

这三个概念的定义比较容易混淆，描述起来也比较空洞。我举个例子说明一下，你一看应该就能明白：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/99.png)

## 二叉树（Binary Tree）
二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是`左子节点`和`右子节点`。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。我画的这几个都是二叉树。以此类推，你可以想象一下四叉树、八叉树长什么样子：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/100.png)

其中，编号 2 的二叉树中，叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫做`满二叉树`；编号 3 的二叉树中，叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做`完全二叉树`。

满二叉树很好理解，也很好识别，但是完全二叉树，有的人可能就分不清了。我画了几个完全二叉树和非完全二叉树的例子，你可以对比着看看：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/101.png)

想要存储一棵二叉树，我们有两种方法，**一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法**。我们先来看比较简单、直观的`链式存储法`。从图中你应该可以很清楚地看到，每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。我们只要拎住根节点，就可以通过左右子节点的指针，把整棵树都串起来。这种存储方式我们比较常用。大部分二叉树代码都是通过这种结构来实现的：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/102.png)

我们再来看，基于数组的`顺序存储法`。我们把根节点存储在下标 i=1 的位置，那左子节点存储在下标 2\*i=2 的位置，右子节点存储在 2\*i+1=3 的位置。以此类推，B 节点的左子节点存储在 2\*i=2\*2=4 的位置，右子节点存储在 2\*i+1=2\*2+1=5 的位置：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/103.png)

我来总结一下，如果节点 X 存储在数组中下标为 i 的位置，下标为 2\*i 的位置存储的就是左子节点，下标为 2\*i+1 的位置存储的就是右子节点。反过来，**下标为 i/2 的位置存储就是它的父节点**。通过这种方式，我们只要知道根节点存储的位置（一般情况下，**为了方便计算子节点，根节点会存储在下标为 1 的位置**），这样就可以通过下标计算，把整棵树都串起来。

不过，我刚刚举的例子是一棵完全二叉树，所以仅仅浪费了一个下标为 0 的存储位置。如果是**非完全二叉树，其实会浪费比较多的数组存储空间**。你可以看我举的下面这个例子：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/104.png)

## 二叉树的遍历
经典的方法有三种，`前序遍历`、`中序遍历`和`后序遍历`。其中，前、中、后序，表示的是**节点与它的左右子树节点遍历打印的先后顺序**：
- 前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树；
- 中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树；
- 后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身；

![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/105.png)

实际上，**二叉树的前、中、后序遍历就是一个递归的过程**。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树。写递归代码的关键，就是看能不能写出递推公式，而写递推公式的关键就是，**如果要解决问题 A，就假设子问题 B、C 已经解决**，然后再来看如何利用 B、C 来解决 A。所以，我们可以把前、中、后序遍历的递推公式都写出来：
```cpp
// 前序遍历的递推公式
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)

// 中序遍历的递推公式
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)

// 后序遍历的递推公式
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r
```

有了递推公式，代码写起来就简单多了：
```cpp
void preOrder(Node* root) {
    if (root == null) {
        return;
    }
    print root // 此处为伪代码，表示打印 root 节点
    preOrder(root->left);
    preOrder(root->right);
}

void inOrder(Node* root) {
    if (root == null) {
        return;
    }
    inOrder(root->left);
    print root // 此处为伪代码，表示打印 root 节点
    inOrder(root->right);
}

void postOrder(Node* root) {
    if (root == null) {
        return;
    }
    postOrder(root->left);
    postOrder(root->right);
    print root // 此处为伪代码，表示打印 root 节点
}
```

从我前面画的前、中、后序遍历的顺序图，可以看出来，每个节点最多会被访问两次，所以**遍历操作的时间复杂度，跟节点的个数 n 成正比**，也就是说二叉树遍历的时间复杂度是 O(n)。

## 二叉查找树（Binary Search Tree）
二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。顾名思义，二叉查找树是为了实现快速查找而生的。不过，它不仅仅支持快速查找一个数据，**还支持快速插入、删除一个数据**。这些都依赖于二叉查找树的特殊结构。二叉查找树要求，在树中的任意一个节点，其**左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值**：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/106.png)

### 二叉查找树的查找操作
首先，我们看如何在二叉查找树中查找一个节点。我们先取根节点，如果它等于我们要查找的数据，那就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/107.png)

这里我把查找的代码实现了一下，贴在下面了，结合代码，理解起来会更加容易：
```java
public class BinarySearchTree {
    private Node tree;

    public Node find(int data) {
        Node p = tree;
        while (p != null) {
            if (data < p.data) {
                p = p.left;
            }
            else if (data > p.data) {
                p = p.right;
            }
            else {
                return p;
            }
        }
        return null;
    }

    public static class Node {
        private int data;
        private Node left;
        private Node right;

        public Node(int data) {
            this.data = data;
        }
    }
}
```

### 二叉查找树的插入操作
二叉查找树的插入过程有点类似查找操作。**如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置**；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/108.png)

同样，插入的代码我也实现了一下，贴在下面：
```java
public void insert(int data) {
    if (tree == null) {
        tree = new Node(data);
        return;
    }

    Node p = tree;
    while (p != null) {
        if (data > p.data) {
            if (p.right == null) {
                p.right = new Node(data);
                return;
            }
            p = p.right;
        } 
        else { 
            // data < p.data
            if (p.left == null) {
                p.left = new Node(data);
                return;
            }
            p = p.left;
        }
    }
}
```

### 二叉查找树的删除操作
二叉查找树的查找、插入操作都比较简单易懂，但是它的删除操作就比较复杂了。针对要删除节点的子节点个数的不同，我们需要分三种情况来处理：
1. 如果要删除的节点没有子节点，我们只需要直接将父节点中，指向要删除节点的指针置为 null。比如图中的删除节点 55；
2. 如果要删除的节点只有一个子节点（只有左子节点或者右子节点），我们只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了。比如图中的删除节点 13；
3. 如果要删除的节点有两个子节点，这就比较复杂了。我们需要**找到这个节点的右子树中的最小节点，把它替换到要删除的节点上**。然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以，我们可以**应用上面两条规则来删除这个最小节点**。比如图中的删除节点 18；

![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/109.png)

老规矩，我还是把删除的代码贴在这里：
```java
public void delete(int data) {
    Node p = tree;  // p 指向要删除的节点，初始化指向根节点
    Node pp = null; // pp 记录的是 p 的父节点
    while (p != null && p.data != data) {
        pp = p;
        if (data > p.data) {
            p = p.right;
        }
        else { 
            p = p.left;
        }
    }
    if (p == null) {
        // 没有找到
        return;
    }
    // 要删除的节点有两个子节点
    if (p.left != null && p.right != null) { 
        // 查找右子树中最小节点
        Node minP = p.right;
        Node minPP = p; // minPP 表示 minP 的父节点
        while (minP.left != null) {
            minPP = minP;
            minP = minP.left;
        }
        p.data = minP.data; // 将 minP 的数据替换到 p 中，下面就变成了删除 minP 了
        p = minP;
        pp = minPP;
    }
    // 删除节点是叶子节点或者仅有一个子节点
    Node child; // p 的子节点
    if (p.left != null) {
        child = p.left;
    }
    else if (p.right != null) {
        child = p.right;
    }
    else {
        child = null;
    }

    if (pp == null) {
        // 删除的是根节点
        tree = child;
    }
    else if (pp.left == p) {
        pp.left = child;
    }
    else {
        pp.right = child;
    }
}
```

实际上，关于二叉查找树的删除操作，还有个非常简单、取巧的方法，就是**单纯将要删除的节点标记为“已删除”，但是并不真正从树中将这个节点去掉**。这样原本删除的节点还需要存储在内存中，比较浪费内存空间，但是删除操作就变得简单了很多。而且，这种处理方法也并没有增加插入、查找操作代码实现的难度。

### 二叉查找树的其他操作
除了插入、删除、查找操作之外，二叉查找树中还可以支持**快速地查找最大节点和最小节点、前驱节点和后继节点**。二叉查找树除了支持上面几个操作之外，还有一个重要的特性，就是**中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)**，非常高效。因此，二叉查找树也叫作二叉排序树。

## 支持重复数据的二叉查找树
前面讲二叉查找树的时候，我们默认树中节点存储的都是数字。很多时候，**在实际的软件开发中，我们在二叉查找树中存储的，是一个包含很多字段的对象**。我们利用对象的某个字段作为键值（key）来构建二叉查找树。我们把对象中的其他字段叫作`卫星数据`。

如果存储的两个对象键值相同，我这里有两种解决方法：
1. 二叉查找树中每一个节点不仅会存储一个数据，因此我们**通过链表和支持动态扩容的数组等数据结构**，把值相同的数据都存储在同一个节点上；
2. 比较不好理解，不过更加优雅。每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，**把这个新插入的数据当作大于这个节点的值来处理**：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/110.png)
    当要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是**继续在右子树中查找，直到遇到叶子节点，才停止**。这样就可以把键值等于要查找值的所有节点都找出来：
    ![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/111.png)
    对于删除操作，我们也需要先查找到每个要删除的节点，然后再**按前面讲的删除操作的方法，依次删除**：
    ![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/112.png)

## 二叉查找树的时间复杂度分析
实际上，二叉查找树的形态各式各样。比如这个图中，对于同一组数据，我们构造了三种二叉查找树。它们的查找、插入、删除操作的执行效率都是不一样的。图中第一种二叉查找树，**根节点的左右子树极度不平衡，已经退化成了链表**，所以查找的时间复杂度就变成了 O(n)：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/113.png)

我刚刚其实分析了一种最糟糕的情况，我们现在来分析一个最理想的情况，二叉查找树是一棵完全二叉树（或满二叉树）。不管操作是插入、删除还是查找，**时间复杂度其实都跟树的高度成正比，也就是 O(height)**。对于完全二叉树来说，它包含的节点个数在 1 个到 2^(L-1) 个之间（我们假设最大层数是 L）。如果我们把每一层的节点个数加起来就是总的节点个数 n。也就是说，如果节点的个数是 n，那么 n 满足这样一个关系：
```java
n >= 1+2+4+8+...+2^(L-2)+1
n <= 1+2+4+8+...+2^(L-2)+2^(L-1)
```

借助等比数列的求和公式，我们可以计算出，L 的范围是[log2(n+1), log2n + 1]。完全二叉树的层数小于等于 log2n + 1，也就是说，完全二叉树的高度小于等于 log2n。

## 相对于散列表的优势
我们在散列表那节中讲过，散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 O(1)，非常高效。而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 O(logn)，相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢：
- 散列表中的数据是无序存储的，如果要**输出有序的数据，需要先进行排序**。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列；
- 散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的**平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)**；
- 笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但**因为哈希冲突的存在，这个常量不一定比 logn 小**，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高；
- 散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。**平衡二叉查找树只需要考虑平衡性这一个问题**，而且这个问题的解决方案比较成熟、固定；
- 为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会**浪费一定的存储空间**；

## LeetCode
[Invert Binary Tree](https://leetcode.com/problems/invert-binary-tree/)
[Maximum Depth of Binary Tree](https://leetcode.com/problems/maximum-depth-of-binary-tree/)
[Validate Binary Search Tree](https://leetcode.com/problems/validate-binary-search-tree/)
[Path Sum](https://leetcode.com/problems/path-sum/)
