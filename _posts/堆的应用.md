---
title: 堆的应用
tags:
  - CLRS
abbrlink: 1654306293
date: 2021-01-07 23:58:31
---
## 堆的应用一：优先级队列
优先级队列，顾名思义，它首先应该是一个队列。不过，在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，**优先级最高的，最先出队**。一个堆就可以看作一个优先级队列，很多时候，它们只是概念上的区分而已。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。

优先级队列的应用场景非常多。比如，赫夫曼编码、图的最短路径、最小生成树算法等等。不仅如此，很多语言中，都提供了优先级队列的实现，比如，Java 的 PriorityQueue，C++ 的 priority_queue 等。只讲这些应用场景比较空泛，现在，我举两个具体的例子：
1. 合并有序小文件：
假设我们有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是有序的字符串。我们希望将这些 100 个小文件合并成一个有序的大文件。我们用数组这种数据结构，来存储从小文件中取出来的字符串。**每次从数组中取最小字符串，都需要循环遍历整个数组**，显然，这不是很高效。
这里就可以用到优先级队列，也可以说是堆。我们将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。我们将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。我们知道，删除堆顶数据和往堆中插入数据的时间复杂度都是 O(logn)，n 表示堆中的数据个数，这里就是 100，比原来数组存储的方式高效了很多；

<!--more-->
2. 高性能定时器：
假设我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。定时器每过一个很小的单位时间（比如 1 秒），就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/153.png)
但是，这样每过 1 秒就扫描一遍任务列表的做法比较低效，主要原因有两点：第一，任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的；第二，每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。
针对这些问题，我们就可以用优先级队列来解决。我们按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。这样，定时器就不需要每隔 1 秒就扫描一遍任务列表了。它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。这个时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。这样，定时器就可以设定在 T 秒之后，再来执行任务。从当前时间点到 T-1 秒这段时间里，定时器都不需要做任何事情。
当 T 秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。这样，定时器**既不用间隔 1 秒就轮询一次，也不用遍历整个任务列表**，性能也就提高了；

## 堆的应用二：利用堆求 Top K
我们可以**维护一个大小为 K 的小顶堆**，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前 K 大数据了；并且，无论任何时候需要查询当前的前 K 大数据，我们都可以立刻返回。

遍历数组需要 O(n) 的时间复杂度，一次堆化操作需要 O(logK) 的时间复杂度，所以**最坏情况下，n 个元素都入堆一次，时间复杂度就是 O(nlogK)**。

## 堆的应用三：利用堆求中位数
中位数，顾名思义，就是处在中间位置的那个数。如果数据的个数是奇数，把数据从小到大排列，那第 n/2​+1 个数据就是中位数；如果数据的个数是偶数的话，那处于中间位置的数据有两个，第 n/2​ 个和第 n/2​+1 个数据，这个时候，我们可以**随意取一个作为中位数，比如取两个数中靠前的那个**，就是第 n/2​ 个数据：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/154.png)

对于一组`静态数据`，中位数是固定的，我们可以先排序，第 n/2​ 个数据就是中位数。每次询问中位数的时候，我们直接返回这个固定的值就好了。所以，**尽管排序的代价比较大，但是边际成本会很小**。但是，如果我们面对的是`动态数据`集合，中位数在不停地变动，如果再用先排序的方法，每次询问中位数的时候，都要先进行排序，那效率就不高了。

我们需要维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且**小顶堆中的数据都大于大顶堆中的数据**。也就是说，如果有 n 个数据，n 是偶数，我们从小到大排序，那前 n/2​ 个数据存储在大顶堆中，后 n/2​ 个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是我们要找的中位数。如果 n 是奇数，情况是类似的，大顶堆就存储 n/2​+1 个数据，小顶堆中就存储 n/2​ 个数据：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/155.png)

**如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆**；否则，我们就将这个新数据插入到小顶堆。这个时候就有可能出现，两个堆中的数据个数不符合前面约定的情况，我们可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定：
![](https://raw.githubusercontent.com/necusjz/p/master/CLRS/geek/156.png)

插入数据因为需要涉及堆化，所以时间复杂度变成了 O(logn)，但是求中位数我们只需要返回大顶堆的堆顶元素就可以了，所以时间复杂度就是 O(1)。实际上，利用两个堆不仅可以快速求出中位数，还可以快速求其他百分位的数据，比如：快速求接口的 99% 响应时间。

我们维护两个堆，一个大顶堆，一个小顶堆。假设当前总数据的个数是 n，大顶堆中保存 n\*99% 个数据，小顶堆中保存 n\*1% 个数据。**大顶堆堆顶的数据就是我们要找的 99% 响应时间**。为了保持大顶堆中的数据占 99%，小顶堆中的数据占 1%，在每次新插入数据之后，我们都要重新计算，这个时候大顶堆和小顶堆中的数据个数，是否还符合 99:1 这个比例。如果不符合，我们就将一个堆中的数据移动到另一个堆，直到满足这个比例。

通过这样的方法，**每次插入数据，可能会涉及几个数据的堆化操作，所以时间复杂度是 O(logn)**。每次求 99% 响应时间的时候，直接返回大顶堆中的堆顶数据即可，时间复杂度是 O(1)。

## 如何快速获取到 Top 10 最热门的搜索关键词
搜索引擎每天会接收大量的用户搜索请求，它会把这些用户输入的搜索关键词记录下来，然后再离线地统计分析，得到最热门的 Top 10 搜索关键词。假设现在我们有一个包含 10 亿个搜索关键词的日志文件。处理这个问题，有很多高级的解决方法，比如使用 MapReduce 等。但是，如果我们**将处理的场景限定为单机，可以使用的内存为 1GB**。那这个问题该如何解决呢？

因为用户搜索的关键词，有很多可能都是重复的，所以我们首先要统计每个搜索关键词出现的频率。我们可以**通过散列表、平衡二叉查找树或者其他一些支持快速查找、插入的数据结构，来记录关键词及其出现的次数**。假设我们选用散列表。我们就顺序扫描这 10 亿个搜索关键词。当扫描到某个关键词时，我们去散列表中查询。如果存在，我们就将对应的次数加一；如果不存在，我们就将它插入到散列表，并记录次数为 1。以此类推，等遍历完这 10 亿个搜索关键词之后，散列表中就存储了不重复的搜索关键词以及出现的次数。

然后，我们再根据前面讲的用堆求 Top K 的方法，**建立一个大小为 10 的小顶堆**，遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比。如果出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中。以此类推，当遍历完整个散列表中的搜索关键词之后，堆中的搜索关键词就是出现次数最多的 Top 10 搜索关键词了。

上面的解决思路其实存在漏洞。10 亿的关键词还是很多的。我们假设 10 亿条搜索关键词中不重复的有 1 亿条，如果每个搜索关键词的平均长度是 50 个字节，那存储 1 亿个关键词起码需要 5GB 的内存空间，而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以消耗的内存空间就更多了。而我们的机器只有 1GB 的可用内存空间，所以我们**无法一次性将所有的搜索关键词加入到内存中**。

相同数据经过哈希算法得到的哈希值是一样的，我们将 10 亿条搜索关键词先通过哈希算法分片到 10 个文件中。具体可以这样做：我们创建 10 个空文件 00, 01, 02, ..., 09。我们遍历这 10 亿个关键词，并且**通过某个哈希算法对其求哈希值，然后哈希值同 10 取模**，得到的结果就是这个搜索关键词应该被分到的文件编号。对这 10 亿个关键词分片之后，总的大小大约是 500MB。1GB 的内存完全可以放得下。

我们针对每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10，然后把这个 10 个 Top 10 放在一块，然后**取这 100 个关键词中，出现次数最多的 10 个关键词**，这就是这 10 亿数据中的 Top 10 最频繁的搜索关键词了。
